---
title: "Meta Analysis Psilocybin Cognition: Reaction Time"
author: "Parsa Yousefi"
date: "`r Sys.Date()`"
output: html_document
---

# setup
```{r setup, include=FALSE}
# knitr::opts_chunk$set(echo = TRUE)a
# install.packages("readxl")
# install.packages("rmarkdown")
# install.packages("metafor")
# install.packages("meta")
# install.packages("dplyr")
# install.packages("gridExtra")
# install.packages("caret")
# install.packages("forrest")
# install.packages("tidyverse")
# install.packages("mvmeta")
# install.packages("plotly")
# install.packages("RColorBrewer")


# library("mvmeta")
library(tidyverse)
library("caret")
library("rmarkdown")
library("stringr")
library("readxl")
library("metafor")
library("meta")
library("dplyr")
library("ggplot2")
library("gridExtra")
library("plotly")
library("RColorBrewer")
source("transform_functions.r")


if (!require("remotes")) {
    install.packages("remotes")
}
# Define data file
datafile <- "Overview_Studies.xlsx"
```

# Load Data
```{r Data Preparation}
Read_Prepare <- function(datafile) {
    # Read the overview sheet
    data <- as.data.frame(read_excel(datafile, sheet = "Overview"))

    # Define columns to select using all_of() for safe selection
    cols_to_select <- c(
        "ID", "ES_ID", "CognitiveFunction", "N_final", "ES_final_RT", "ES_final_ACC",
        "ES_final_other", "Timepoint", "PlotLabel", "DoseLabel", "EF_sensitivity"
    )

    # Select the columns using all_of() to avoid tidyselect warning
    data <- select(data, all_of(cols_to_select))

    # Preprocessing: Assign numeric IDs and convert numeric columns

    numeric_cols <- c("N_final", "ES_final_RT", "ES_final_ACC", "ES_final_other", "Timepoint", "EF_sensitivity")
    data[numeric_cols] <- lapply(data[numeric_cols], function(x) {
        as.numeric(as.character(x))
    })

    # Convert all other columns that are not in numeric_cols to factors
    non_numeric_cols <- setdiff(names(data), numeric_cols)
    data[non_numeric_cols] <- lapply(data[non_numeric_cols], as.factor)

    # Handle potential NA introduction by coercion
    if (any(sapply(data[numeric_cols], is.na))) {
        warning("NA values were introduced by coercion.")
    }

    # Clean up text data
    text_cols <- setdiff(names(data), numeric_cols)
    data[text_cols] <- lapply(data[text_cols], gsub, pattern = "\r\n|\r|\n", replacement = "")

    # Filter data by dose categories
    data_micro <- filter(data, DoseLabel == "Micro")
    data_low <- filter(data, DoseLabel == "Low")
    data_mid <- filter(data, DoseLabel == "Medium")
    data_high <- filter(data, DoseLabel == "High")

    # Combine all the filtered data back into one dataframe in the correct order
    data_combined <- bind_rows(data_micro, data_low, data_mid, data_high)

    # Ensure all necessary dose data frames are correctly combined
    if (!is.null(data_combined) && nrow(data_combined) == nrow(data)) {
        # Assign dosage categories
        data_combined$dosage_cat_all <- c(
            rep(0, nrow(data_micro)),
            rep(1, nrow(data_low)),
            rep(2, nrow(data_mid)),
            rep(3, nrow(data_high))
        )
        data_combined$dosage_cat_micro <- c(
            rep(0, nrow(data_micro)),
            rep(1, nrow(data_low) + nrow(data_mid) + nrow(data_high))
        )
        data_combined$dosage_cat_microlow_vs_midhigh <- c(
            rep(1, nrow(data_low) + nrow(data_micro)),
            rep(2, nrow(data_mid) + nrow(data_high))
        )
    } else {
        stop("Row counts do not match after combining data subsets. Check the filtering criteria.")
    }


    return(data_combined)
}


data <- Read_Prepare(datafile)
```

```{r add varaince of cohens d}
# add the variance of the Cohen's d to the dataset
# https://stats.stackexchange.com/questions/144084/variance-of-cohens-d-statistic
# https://stats.stackexchange.com/questions/495015/what-is-the-formula-for-the-standard-error-of-cohens-d
AddCohensDVariance <- function(data) {
    # Ensure 'data' is a data frame
    if (!is.data.frame(data)) {
        stop("The 'data' argument must be a data frame.")
    }

    # Initialize variance columns with NA
    data$ES_var_RT <- NA
    data$ES_var_ACC <- NA
    data$ES_var_other <- NA

    # Define split factor
    splitfactor <- 2

    # Loop through each row to calculate variances
    for (i in 1:nrow(data)) {
        N_sum <- data$N_final[i]
        N_prod <- (data$N_final[i] / splitfactor) * (data$N_final[i] / splitfactor)

        # Calculating variance for each effect size
        data$ES_var_RT[i] <- (N_sum / N_prod) + (data$ES_final_RT[i]^2 / (2 * N_sum))
        data$ES_var_ACC[i] <- (N_sum / N_prod) + (data$ES_final_ACC[i]^2 / (2 * N_sum))
        data$ES_var_other[i] <- (N_sum / N_prod) + (data$ES_final_other[i]^2 / (2 * N_sum))
    }

    return(data)
}

data <- AddCohensDVariance(data)
```

# select data
```{r RT Selection}
# Define the columns to select
cols_to_select <- c(
    "ID", "ES_ID", "CognitiveFunction", "N_final", "ES_final_RT",
    "ES_var_RT", "Timepoint", "PlotLabel", "DoseLabel", "EF_sensitivity", "dosage_cat_all", "dosage_cat_micro", "dosage_cat_microlow_vs_midhigh"
)

# Select the columns and filter rows where ES_final_RT is not NA
data_RT <- subset(data, select = cols_to_select, !is.na(ES_final_RT))
data_RT$CognitiveFunction <- as.factor(data_RT$CognitiveFunction)
data_RT$DoseLabel <- as.factor(data_RT$DoseLabel)
data_RT$EF_sensitivity <- as.factor(data_RT$EF_sensitivity)
data_RT$dosage_cat_all <- as.factor(data_RT$dosage_cat_all)
data_RT$ES_ID <- as.numeric(data_RT$ES_ID)
data_RT$ID <- as.factor(data_RT$ID)

# Number of entries for RT measure
n_rows <- nrow(data_RT)
n_unique_ids <- length(unique(data_RT$ID))


# Print the results
cat("Number of entries for RT measure:", n_rows, "\n")
cat("Number of unique IDs:", n_unique_ids, "\n")
```

```{r ACC Selection}
# Define the columns to select
cols_to_select_ACC <- c(
    "ID", "ES_ID", "CognitiveFunction", "N_final", "ES_final_ACC",
    "ES_var_ACC", "Timepoint", "PlotLabel", "DoseLabel", "EF_sensitivity", "dosage_cat_all", "dosage_cat_micro", "dosage_cat_microlow_vs_midhigh"
)

# Select the columns and filter rows where ES_final_ACC is not NA
data_ACC <- subset(data, select = cols_to_select_ACC, !is.na(ES_final_ACC))

data_ACC$CognitiveFunction <- as.factor(data_ACC$CognitiveFunction)
data_ACC$DoseLabel <- as.factor(data_ACC$DoseLabel)
data_ACC$EF_sensitivity <- as.factor(data_ACC$EF_sensitivity)
data_ACC$dosage_cat_all <- as.factor(data_ACC$dosage_cat_all)
data_ACC$ES_ID <- as.numeric(data_ACC$ES_ID)
data_ACC$ID <- as.factor(data_ACC$ID)



# Number of entries for ACC measure
n_rows_ACC <- nrow(data_ACC)
n_unique_ids_ACC <- length(unique(data_ACC$ID))


# Print the results
cat("Number of entries for ACC measure:", n_rows_ACC, "\n")
cat("Number of unique IDs:", n_unique_ids_ACC, "\n")
```

# 3.4 Results
# 3.4.1 Reaction Time

```{r calculate_meta function}
calculate_meta <- function(RT = FALSE, ACC = FALSE) {
    library(metafor) # Load the metafor library

    # Select the appropriate dataset
    if (RT) {
        data <- data_RT
        effect_size_col <- "ES_final_RT"
        variance_col <- "ES_var_RT"
    } else if (ACC) {
        data <- data_ACC
        effect_size_col <- "ES_final_ACC"
        variance_col <- "ES_var_ACC"
    } else {
        stop("Either RT or ACC must be set to TRUE.")
    }

    # Order data by ID
    data <- data[order(data$ID), ]

    # Initialize a list to store the results
    model_results <- list()

    # Fit the models

    # Fit the nested model
    model_multi <- rma.mv(
        yi = data[[effect_size_col]],
        V = data[[variance_col]],
        random = ~ 1 | ID / ES_ID,
        data = data,
        test = "t",
        method = "REML",
        slab = data$ES_ID
    )

    # Fit the non-nested model (same random structure without sigma^2 = 0 constraint)
    model_plain <- rma.mv(
        yi = data[[effect_size_col]],
        V = data[[variance_col]],
        random = ~ 1 | ID / ES_ID,
        data = data,
        test = "t",
        method = "REML",
        slab = data$ES_ID,
        sigma2 = c(0, NA)
    )

    # Fit the univariate model
    model_uni <- rma.uni(
        yi = data[[effect_size_col]],
        vi = data[[variance_col]],
        # random = ~ 1 | ID/ES_ID,
        data = data,
        test = "t",
        method = "REML",
        slab = data$ES_ID
    )


    # Perform variance analysis and model comparison
    variance_analysis <- mlm.variance.distribution(model_multi)
    model_comparison <- anova(model_multi, model_plain)

    # Store results in the list
    model_results <- list(
        model_multi = model_multi,
        model_plain = model_plain,
        model_uni = model_uni,
        variance_analysis = variance_analysis,
        model_comparison = model_comparison
    )


    return(model_results)
}
summary(calculate_meta(RT = TRUE)$model_multi)
calculate_meta(RT = TRUE)$variance_analysis$ResultsTable
calculate_meta(RT = TRUE)$variance_analysis$TotalI2

# calculate_meta(RT=TRUE, multilevel=TRUE)$model_uni
```


# 3.4.1.1 Outliers and influential cases RT

```{r Figure S6}
library(ggplot2)
library(metafor) # Ensure metafor is loaded for meta-analysis functions

identify_outliers <- function(data_type, multi = FALSE) {
    if (data_type != "RT" && data_type != "ACC") {
        stop("data_type must be 'RT' or 'ACC'.")
    }

    # Select data and set parameters
    if (data_type == "RT") {
        data <- as.data.frame(data_RT)
        effect_size_col <- "ES_final_RT"
        variance_col <- "ES_var_RT"
        plottitle <- "Reaction Time Effect Size Distribution"
    } else if (data_type == "ACC") {
        data <- as.data.frame(data_ACC)
        effect_size_col <- "ES_final_ACC"
        variance_col <- "ES_var_ACC"
        plottitle <- "Accuracy Effect Size Distribution"
    }

    # Perform meta-analysis using calculate_meta function
    meta_results <- calculate_meta(RT = (data_type == "RT"), ACC = (data_type == "ACC"), multilevel = multi)
    model <- meta_results$model_multi # Assuming this is the correct model object

    # Extracting the confidence intervals from the model
    overall_ci_lb <- coef(summary(model))["intrcpt", "ci.lb"]
    overall_ci_ub <- coef(summary(model))["intrcpt", "ci.ub"]

    # Calculate CI for each observed effect size in the dataset
    data$d <- data[[effect_size_col]]
    data$upperci <- data$d + 1.96 * sqrt(data[[variance_col]])
    data$lowerci <- data$d - 1.96 * sqrt(data[[variance_col]])
    data$outlier <- with(data, upperci < overall_ci_lb | lowerci > overall_ci_ub)

    # Plotting the data with outliers highlighted
    plot <- ggplot(data, aes(x = d, colour = outlier, fill = outlier)) +
        geom_histogram(alpha = 0.5, bins = 30) +
        geom_vline(xintercept = coef(model)["intrcpt"], linetype = "dashed", color = "blue") +
        scale_fill_manual(values = c("FALSE" = "grey", "TRUE" = "red")) +
        scale_color_manual(values = c("FALSE" = "black", "TRUE" = "red")) +
        labs(title = plottitle, x = "Effect Size", y = "Frequency") +
        theme_bw()

    # Filter data to remove outliers and re-run meta-analysis if required
    filtered_data <- data[!data$outlier, ]
    if (nrow(filtered_data) > 1) { # Check if there is enough data to re-run the meta-analysis
        model_no_outlier <- rma.mv(
            yi = filtered_data[[effect_size_col]],
            V = filtered_data[[variance_col]],
            random = ~ 1 | ID / ES_ID,
            data = filtered_data,
            method = "REML"
        )
        summary_no_outlier <- summary(model_no_outlier)
    } else {
        summary_no_outlier <- NULL
    }

    # Prepare the return list
    results <- list(
        plot = plot,
        outliers = data[data$outlier, ],
        model_summary = summary_no_outlier
    )

    return(results)
}

# Example usage:
results <- identify_outliers("RT", multi = TRUE)
print(results$plot)
if (!is.null(results$model_summary)) {
    print(summary(results$model_summary))
}
```

```{r Figure S7}
calculate_residuals <- function(RT = FALSE, ACC = FALSE, outlier_threshold = 2) {
    # Ensure that either RT or ACC is TRUE, but not both
    if (RT == TRUE && ACC == TRUE) {
        stop("Only one of RT or ACC should be TRUE")
    } else if (RT == FALSE && ACC == FALSE) {
        stop("At least one of RT or ACC should be TRUE")
    }

    # Select the appropriate data based on RT or ACC
    data_selected <- if (RT) {
        plottitle <- "Reaction Time"
        calculate_meta(RT = TRUE )$model_multi
    } else if (ACC) {
        plottitle <- "Accuracy"
        calculate_meta(ACC = TRUE)$model_multi
    }

    # Standardized residuals
    res_mod_all_ml <- rstandard(data_selected)
    res_mod_all_plain <- residuals(data_selected)

    # Determine the appropriate dataset for the ID
    data_for_ID <- if (RT) data_RT else data_ACC


    # Set up the plotting area
    par(mfrow = c(1, 2))

    # Boxplot
    data_for_boxplot <- data.frame(z = res_mod_all_ml$z, ID = data_for_ID$ES_ID)
    boxplot <- ggplot(data_for_boxplot, aes(x = "", y = z)) +
        geom_boxplot() +
        theme_gray() +
        labs(y = "Z values", title = paste("Boxplot of Standardized Residuals for", plottitle))
    # Barplot
    data_for_barplot <- data.frame(ID = data_for_ID$ES_ID, Residuals = res_mod_all_ml$z)
    barplot <- ggplot(data_for_barplot, aes(x = ID, y = Residuals)) +
        geom_bar(stat = "identity", position = position_dodge()) +
        coord_flip() + # To make barplot horizontal
        theme_gray() +
        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
        labs(x = "ES_ID", y = "Standardized Residuals", title = paste("Barplot of Standardized Residuals for", plottitle))
    # display
    library(gridExtra)
    grid.arrange(boxplot, barplot, ncol = 1)

    # outlier handling:
    # outliers based on standardized residuals > multi_outlier
    outliers_indices <- which(abs(res_mod_all_ml$z) > outlier_threshold)
    # Extract the corresponding rows from the dataset
    outlier_studies <- data_for_ID[outliers_indices, ]

    # outlier studies
    print((outlier_studies))
    return(invisible(res_mod_all_ml))
}

calculate_residuals(RT = TRUE, outlier_threshold = 2)
```

```{r Figure S8}
library(ggplot2)
library(gridExtra) # For arranging ggplot2 plots
run_diagnostics <- function(data_type) {
    if (!data_type %in% c("RT", "ACC")) {
        stop("data_type must be either 'RT' or 'ACC'.")
    }

    # Determine the title prefix based on the data type
    title_prefix <- if (data_type == "RT") "Reaction Time" else "Accuracy"

    # Run the meta-analysis with multilevel modeling
    model <- calculate_meta(RT = data_type == "RT", ACC = data_type == "ACC")$model_multi

    # Set up the plotting area to display three plots side by side
    par(mfrow = c(1, 3))

    # Cook's Distance
    cooks <- cooks.distance(model)
    print(nrow(cooks))
    plot(cooks, type = "h", main = paste("Cook's Distance for", title_prefix), ylab = "Distance", col = "blue")
    abline(h = 4 / (length(cooks) - 2), col = "red", lty = 2)

    # DFBETAS
    dfbetas_values <- dfbetas(model)
    plot(dfbetas_values, main = paste("DFBETAS for", title_prefix), ylab = "DFBETAS", col = "blue")

    # Hat Values
    hatvals <- hatvalues(model, type = "diagonal")
    plot(hatvals, type = "h", main = paste("Hat Values for", title_prefix), ylab = "Leverage", col = "blue")
    abline(h = 2 * mean(hatvals), col = "red", lty = 2)

    # Reset the plotting layout
    par(mfrow = c(1, 1))
}
# Example call to the function for Reaction Time
run_diagnostics("RT")
```

```{r Figure S9}
library(metafor)
library(ggplot2)
library(gridExtra)

# Function to calculate and plot diagnostic measures
diagnostic_analysis <- function(data_type, threshold = 2) {
    # Validate the data type
    if (!data_type %in% c("RT", "ACC")) {
        stop("data_type must be either 'RT' or 'ACC'.")
    }

    # Select the appropriate dataset and calculate the meta-analysis model
    if (data_type == "RT") {
        data <- data_RT
    } else {
        data <- data_ACC
    }
    model <- calculate_meta(RT = data_type == "RT", ACC = data_type == "ACC")$model_multi

    n <- nrow(data)

    # Calculating Cook's Distance
    cooks <- cooks.distance(model)
    print("Number of Cook's Distances:")
    class(cooks)
    outliers_cooks <- which(cooks > 4 / (n - 2))
    print("oputliers cooks")
    data[outliers_cooks, "ES_ID"]


    # Calculating Hat Values
    hatvals <- hatvalues(model)
    class(hatvals)
    outliers_hatvals <- which(hatvals > 2 * mean(hatvals))
    print("outliers hatvals")
    data[outliers_hatvals, "ES_ID"]

    # Calculating DFBETAS
    dfbetas_values <- dfbetas(model)
    outliers_dfbetas <- which(abs(dfbetas_values[, "intrcpt"]) > 2 / sqrt(n))
    print(" outliers dfbetas")
    data[outliers_dfbetas, "ES_ID"]

    outliers <- unique(c(outliers_cooks, outliers_hatvals, outliers_dfbetas))
    # outliers <- unique(c( outliers_hatvals, outliers_dfbetas))

    # Create a data frame with outlier information
    outlier_info <- data.frame(
        ES_ID = data[outliers, "ES_ID"],
        PlotLabel = data[outliers, "PlotLabel"],
        CognitiveFunction = data[outliers, "CognitiveFunction"],
        Criterion = c(
            # rep("Cook's Distance", length(outliers_cooks)),
            rep("Hat Values", length(outliers_hatvals)),
            rep("DFBETAS", length(outliers_dfbetas))
        )
    )

    # Exclude outliers and refit the model
    data_no_outliers <- data[-outliers, ]
    model_no_outliers <- rma.mv(
        yi = data_no_outliers[[ifelse(data_type == "RT", "ES_final_RT", "ES_final_ACC")]],
        V = data_no_outliers[[ifelse(data_type == "RT", "ES_var_RT", "ES_var_ACC")]],
        random = ~ 1 | ID / ES_ID,
        data = data_no_outliers,
        test = "t",
        method = "REML",
        slab = data_no_outliers$ES_ID
    )
    variance_analysis <- mlm.variance.distribution(model_no_outliers)
    # Plotting Cook's Distance
    plot_cooks <- ggplot(
        data.frame(Index = seq_along(cooks), Cooks = cooks),
        aes(x = Index, y = Cooks)
    ) +
        geom_bar(stat = "identity", fill = "skyblue") +
        geom_hline(yintercept = 4 / (n - 2), col = "red", linetype = "dashed") +
        labs(title = "Cook's Distance", x = "Study Index", y = "Distance")

    # Plotting Hat Values
    plot_hatvals <- ggplot(
        data.frame(Index = seq_along(hatvals), Hat = hatvals),
        aes(x = Index, y = Hat)
    ) +
        geom_bar(stat = "identity", fill = "lightgreen") +
        geom_hline(yintercept = 2 * mean(hatvals), col = "red", linetype = "dashed") +
        labs(title = "Hat Values", x = "Study Index", y = "Leverage")

    # Plotting DFBETAS for each coefficient
    plot_dfbetas <- list()
    for (i in seq_along(coef(model))) {
        plot_dfbetas[[i]] <- ggplot(
            data = data.frame(
                Index = seq_along(dfbetas_values[, i]),
                DFBETAS = dfbetas_values[, i]
            ),
            aes(x = Index, y = DFBETAS)
        ) +
            geom_bar(stat = "identity", fill = "orange") +
            geom_hline(
                yintercept = c(-threshold / sqrt(n), threshold / sqrt(n)),
                col = "red", linetype = "dashed"
            ) +
            labs(
                title = paste("DFBETAS for Coefficient", names(coef(model))[i]),
                x = "Study Index", y = "DFBETAS"
            )
    }

    # Arrange plots
    plots <- list(plot_cooks, plot_hatvals)
    plots <- c(plots, plot_dfbetas)
    arranged_plots <- grid.arrange(grobs = plots, ncol = 2)

    # Returning summary information with additional columns
    diagnostic_data <- data.frame(
        # Effectsize_ID = data[, "ES_ID"],
        Study = data[, "PlotLabel"],
        CognitiveFunction = data[, "CognitiveFunction"],
        Cooks_Distance = cooks,
        Leverage = hatvals,
        DFBETAS_intercept = dfbetas_values[, "intrcpt"]
    )

    return(list(
        plots = arranged_plots,
        summary_table = diagnostic_data,
        outlier_info = outlier_info,
        model_no_outliers = model_no_outliers,
        variance_analysis = variance_analysis
    ))
}

# Using the function
# results <- diagnostic_analysis("ACC")

# # Display the arranged plots
# results$plots

# # Display the outlier information
print(diagnostic_analysis("RT")$model_no_outliers)
print(diagnostic_analysis("RT")$outlier_info)


# # Display the summary of diagnostics
# print(diagnostic_analysis("ACC")$model_no_outliers)
# print(diagnostic_analysis("ACC")$outlier_info)


# diagnostic_analysis("ACC")$summary_table
```

# 3.4.1.2 Publication Bias RT
```{r fail safe nrs}

publication_bias <- function(data_type) {
  # Determine which type of data to use
  if (data_type == "RT") {
    model_results <- calculate_meta(RT = TRUE)
    data <- data_RT
  } else if (data_type == "ACC") {
    model_results <- calculate_meta(ACC = TRUE)
    data <- data_ACC
  } else {
    stop("Invalid data type specified. Use 'RT' or 'ACC'.")
  }
  
  # Perform Kendall's tau rank correlation test
  kendalls_tau <- ranktest(x = data$ES_final, vi = data$ES_var)
  print(kendalls_tau)
  
  # Calculate fail-safe numbers
  fsn_rosenthal <- fsn(x = data$ES_final, vi = data$ES_var, type = "Rosenthal")
  print(fsn_rosenthal)
  
  fsn_orwin <- fsn(x = data$ES_final, vi = data$ES_var, type = "Orwin", target = 0.1)
  print(fsn_orwin)
  
  fsn_rosenberg <- fsn(x = data$ES_final, vi = data$ES_var, type = "Rosenberg")
  print(fsn_rosenberg)
}


publication_bias("RT")

```
```{r Eggers test}

mod_egger <- function(data_type) {
  # Determine which type of data and model to use
  if (data_type == "RT") {
    model_results <- calculate_meta(RT = TRUE)
    data <- data_RT
    yi <- data$ES_final_RT
    V <- data$ES_var_RT
  } else if (data_type == "ACC") {
    model_results <- calculate_meta(ACC = TRUE)
    data <- data_ACC
    yi <- data$ES_final_ACC
    V <- data$ES_var_ACC
  } else {
    stop("Invalid data type specified. Use 'RT' or 'ACC'.")
  }
  
  # Perform the regression analysis using rma.mv
  mod_egger <- rma.mv(
    yi = yi,
    V = V,
    mods = ~ I(1 / sqrt(V)),  # precision as moderator
    random = ~ 1 | ID/ ES_ID,
    data = data
  )
  # Print the summary of the model
  summary(mod_egger)
}

# Example usage:
mod_egger("RT")

```
```{r Figure 4 Funnel plot Function}
funnel_plot <- function(RT = FALSE, ACC = FALSE) {
    library(metafor)
    library(RColorBrewer)

    # Fetch the model results using calculate_meta
    if (RT) {
        model_results <- calculate_meta(RT = TRUE)
        forest_title <- "Forest plot for the multilevel model of Reaction Time"
        funnel_title <- "Funnel plot for the multilevel model of Reaction Time"
        plot_data <- data_RT
        plot_data$yi <- plot_data$ES_final_RT
        plot_data$sei <- sqrt(plot_data$ES_var_RT)
        xlab_text <- "Reaction Time (Hedges' g)"
        xlim_values <- c(-1, 3)
        ylim_values <- c(0.6, 0)
        color_points <- brewer.pal(nrow(unique(plot_data$PlotLabel)), "Dark2")
    } else if (ACC) {
        model_results <- calculate_meta(ACC = TRUE)
        forest_title <- "Forest plot for the multilevel model of Accuracy"
        funnel_title <- "Funnel plot for the multilevel model of Accuracy"
        plot_data <- data_ACC
        plot_data$yi <- plot_data$ES_final_ACC
        plot_data$sei <- sqrt(plot_data$ES_var_ACC)
        xlab_text <- "Accuracy (Hedges' g)"
        xlim_values <- c(-2.5, 2)
        ylim_values <- c(0.9, 0)
        color_points <- brewer.pal(nrow(unique(plot_data$PlotLabel)), "Paired")
    } else {
        stop("Either RT or ACC must be set to TRUE.")
    }

    color_mapping <- setNames(color_points, unique(plot_data$PlotLabel))
    
    # Create a mapping for shapes based on DoseLabel
    shape_mapping <- setNames(c(16, 17, 18, 19), unique(plot_data$CognitiveFunction))
    

   # Create a mapping for sizes based on DoseLabel (example sizes, adjust as needed)
    size_mapping <- setNames(seq(1, length(unique(plot_data$DoseLabel))), unique(plot_data$DoseLabel)) 

    model <- model_results$model_multi
    model_uni <- model_results$model_uni
    trim <- trimfill(model_uni)

    # Create a data frame for the points with colors and shapes
    point_data <- data.frame(
        x = plot_data$yi,
        y = plot_data$sei,
        col = color_mapping[plot_data$PlotLabel],
        pch = shape_mapping[plot_data$CognitiveFunction],
        cex = size_mapping[plot_data$DoseLabel]
    )

    # Extract the filled studies
    filled_indices <- trim$fill
    filled_studies <- trim$yi[filled_indices]
    filled_sei <- sqrt(trim$vi[filled_indices])
    print(filled_studies)

    # Set up the graphical environment
    par(mfrow = c(1, 1), tck = -.03, mgp = c(6, 3, 0), mar = c(8, 10, 5, 6), bg = "white",
        cex.main = 1.5, # Font size for the main title
        cex.lab = 3,  # Font size for the axis titles
        cex.axis = 2  # Font size for the axis tick labels
    )

    cantour_shades <- brewer.pal(9,"Blues")[c(2, 4, 6)]

    # Create a contour-enhanced funnel plot
    funnel(model,
        refline2 = model_uni$beta,
        refline = 0,
        lty = c(0, 0),
        level = c(90, 95, 99), # Adding multiple levels for contours
        shade = cantour_shades, 
        label = "none", # Label all points with study labels
        slab = plot_data$ES_ID,
        xlab = xlab_text,
        back = "white",
        cex = 2,
        lwd = 3,
        xlim = xlim_values,
        ylim = ylim_values,
        digits = c(2, 2)
    )

    # Add the points using the points function with varying shapes
    points(point_data$x, point_data$y, col = point_data$col, pch = point_data$pch, cex = point_data$cex)

    # Add filled studies
    points(filled_studies, filled_sei, col = "red", pch = 4, cex = 1.7)

    # Add labels on top of each point
    text(point_data$x, point_data$y, labels = plot_data$ES_ID, pos = 3, offset = 1, cex = 0.9) # 'pos = 3' places the label above the point

    legend_data <- data.frame(ID = unique(plot_data$ID), PlotLabel = unique(plot_data$PlotLabel))
    print(legend_data)

    legend("topright", ncol = 1,
        legend = c("90% CI", "95% CI", "99% CI", "Trim and Fill", legend_data$PlotLabel),
        fill = c(cantour_shades, "red", color_mapping[legend_data$PlotLabel]),
        col = c(NA, NA, NA, NA, NA),
        pch = c(16, 16, 16, 16, rep(16, nrow(legend_data))),
        lty = c(1, 1, 1, rep(NA, nrow(legend_data) + 1)),
        y.intersp = 0.6,
        x.intersp = 0.2
    )
    
    # Reset graphical parameters
    par(mfrow = c(1, 1))
}

funnel_plot(RT = TRUE)




```

```{r baustelle}	
funnel_plot <- function(RT = FALSE, ACC = FALSE) {
    library(metafor)
    library(RColorBrewer)

    # Fetch the model results using calculate_meta
    if (RT) {
        model_results <- calculate_meta(RT = TRUE)
        egger_results <- mod_egger("RT")
        funnel_title <- "Funnel plot for the multilevel model of Reaction Time"
        plot_data <- data_RT
        plot_data$yi <- plot_data$ES_final_RT
        plot_data$sei <- sqrt(plot_data$ES_var_RT)
        xlab_text <- "Reaction Time (Hedges' g)"
        xlim_values <- c(-1, 3)
        ylim_values <- c(0.6, 0.3)
        color_points <- brewer.pal(length(unique(plot_data$PlotLabel)), "Dark2")
    } else if (ACC) {
        model_results <- calculate_meta(ACC = TRUE)
        egger_results <- mod_egger("ACC")
        funnel_title <- "Funnel plot for the multilevel model of Accuracy"
        plot_data <- data_ACC
        plot_data$yi <- plot_data$ES_final_ACC
        plot_data$sei <- sqrt(plot_data$ES_var_ACC)
        xlab_text <- "Accuracy (Hedges' g)"
        xlim_values <- c(-2.5, 2)
        ylim_values <- c(0.8, 0.2)
        color_points <- brewer.pal(length(unique(plot_data$PlotLabel)), "Paired")
    } else {
        stop("Either RT or ACC must be set to TRUE.")
    }

    color_mapping <- setNames(color_points[1:length(unique(plot_data$PlotLabel))], unique(plot_data$PlotLabel))

    # Create a mapping for shapes based on DoseLabel
    shape_mapping <- setNames(c(16, 17, 18, 19)[1:length(unique(plot_data$CognitiveFunction))], unique(plot_data$CognitiveFunction))
    
    # Create a mapping for sizes based on DoseLabel (example sizes, adjust as needed)
    size_mapping <- setNames(seq(1, length(unique(plot_data$DoseLabel)))[1:length(unique(plot_data$DoseLabel))], unique(plot_data$DoseLabel)) 
    

    model <- model_results$model_multi
    model_uni <- model_results$model_uni
    trim <- trimfill(model_uni)


    # Create a data frame for the points with colors and shapes
    point_data <- data.frame(
        x = plot_data$yi,
        y = plot_data$sei,
        col = color_mapping[plot_data$PlotLabel],
        pch = shape_mapping[plot_data$CognitiveFunction],
        cex = size_mapping[rev(plot_data$DoseLabel)]
    )

    # Extract the filled studies
    filled_indices <- trim$fill
    filled_studies <- trim$yi[filled_indices]
    filled_sei <- sqrt(trim$vi[filled_indices])
    print(filled_studies)

    # Set up the graphical environment
    par(mfrow = c(1, 1), tck = -.03, mgp = c(6, 3, 0), mar = c(8, 10, 5, 6), bg = "white",
        cex.main = 1.5, # Font size for the main title
        cex.lab = 3,  # Font size for the axis titles
        cex.axis = 2  # Font size for the axis tick labels
    )

    cantour_shades <- brewer.pal(9,"Blues")[c(2, 4, 6)]

    # Create a contour-enhanced funnel plot
    funnel(model,
        refline2 = c(model_uni$beta),
        refline = c(0),
        lty = c(0, 0),
        level = c(90, 95, 99), # Adding multiple levels for contours
        shade = cantour_shades, 
        label = "none", # Label all points with study labels
        slab = plot_data$ES_ID,
        xlab = xlab_text,
        back = "white",
        cex = 2,
        lwd = 3,
        xlim = xlim_values,
        ylim = ylim_values,
        digits = c(2, 2)
    )

    # Add the points using the points function with varying shapes
    points(point_data$x, point_data$y, col = point_data$col, pch = point_data$pch, cex = point_data$cex)

    # Add filled studies
    points(filled_studies, filled_sei, col = "red", pch = 4, cex = 2)

    # Add labels on top of each point
    text(point_data$x, point_data$y, labels = plot_data$ES_ID, pos = 3, offset = 1.5, cex = 1) # 'pos = 3' places the label above the point

    legend_data <- data.frame(ID = unique(plot_data$ID), PlotLabel = unique(plot_data$PlotLabel))
    print(legend_data)

    # Add legend for color, shape, and size
    # Add legend for confidence intervals and trim-and-fill
    legend("topright", ncol = 1,inset = c(0, 0.255),
        legend = c("90% CI", "95% CI", "99% CI", "Trim and Fill"),
        fill = c(cantour_shades, NA),
        col = c(rep(NA, length(cantour_shades)), "red"),
        pch = c(rep(NA, length(cantour_shades)), 4),
        lty = 0,
        y.intersp = 0.6,
        x.intersp = 0.5,
        text.width = max(strwidth(c("90% CI", "95% CI", "99% CI", "Trim and Fill"))) * 1,
     )
    # Add legend for study labels (colors)
    legend("topright", inset = c(0, 0),
        legend = legend_data$PlotLabel,
        fill = color_mapping[legend_data$PlotLabel],
        col = NA,
        pch = NA,
        #lty = NA,
        y.intersp = 0.6,
        x.intersp = 0.2,
        title = "Study"
    )

    # Add legend for cognitive functions (shapes)
    legend("topright", inset = c(0, 0.143),
        legend = names(shape_mapping),
        col = 1,
        pch = shape_mapping,
        pt.cex = 2,
        #lty = NA,
        y.intersp = 0.6,
        x.intersp = 0.8,
        title = "Cognitive Function"
    )
    
    # Add legend for dose labels (sizes)
    legend("topright", inset = c(0, 0.35),
        legend = names(size_mapping),
        col = 1,
        pch = 1,
        pt.cex = size_mapping,
        #lty = NA,
        y.intersp = 0.8,
        x.intersp = 2,
        title = "Doseage"
    )
    
    
    
    # Reset graphical parameters
    par(mfrow = c(1, 1))
}

funnel_plot(ACC = TRUE)

```



```{r test metaviz}
#install.packages("metaviz")
library(metaviz)

mozart <- data_RT

mozart$d <- mozart$ES_final_RT
mozart$se <- sqrt(mozart$ES_var_RT)



summary_table <- data.frame(
    name = "Summary",
    eventsT = paste(sum(mozart$ai), "/", sum(mozart$ai + mozart$bi), sep = ""),
    eventsC = paste(sum(mozart$ci), "/", sum(mozart$ci + mozart$di), sep = ""))
head(summary_table)

study_table <- data.frame(
  name = mozart[, "PlotLabel"],
  eventsT = paste(mozart$ai, "/", mozart$ai + mozart$bi, sep = ""),
  eventsC = paste(mozart$ci, "/", mozart$ci + mozart$di, sep = ""))
head(study_table)


viz_forest(x = mozart[, c("d", "se")], 
            group = mozart[, "CognitiveFunction"], 
            study_labels = mozart[, c("PlotLabel")],
            summary_label = "Summary effect", xlab = "Cohen d",
            variant = "rain", 
            #type="summary_only", 
            study_table = study_table,
            summary_table = summary_table,
            method ="DL",
            annotate_CI = TRUE)



viz_funnel(mozart[1:10, c("d", "se")], sig_contours = FALSE, addev_contours = TRUE)
funnelinf(mozart[1:10, c("d", "se")],show_solution = TRUE)

```	

# 3.4.1.3 Model comparison Reaction Time
```{r}
calculate_meta(RT = TRUE)$model_comparison
```
```{r}
forest_plot <- function(RT = FALSE, ACC = FALSE) {
  library(metaviz)
  library(RColorBrewer)

  # Fetch the model results using calculate_meta
  if (RT) {
    model_results <- calculate_meta(RT = TRUE)
    plot_data <- data_RT
    plot_data$yi <- plot_data$ES_final_RT
    plot_data$sei <- sqrt(plot_data$ES_var_RT)
    xlab_text <- "Reaction Time (Hedges' g)"
  } else if (ACC) {
    model_results <- calculate_meta(ACC = TRUE)
    plot_data <- data_ACC
    plot_data$yi <- plot_data$ES_final_ACC
    plot_data$sei <- sqrt(plot_data$ES_var_ACC)
    xlab_text <- "Accuracy (Hedges' g)"
  } else {
    stop("Either RT or ACC must be set to TRUE.")
  }

  # Create a data frame for the table
  table_data <- data.frame(
    PlotLabel = plot_data$PlotLabel,
    DoseLabel = plot_data$DoseLabel,
    N_final = plot_data$N_final,
    Timepoint = plot_data$Timepoint,
    CognitiveFunction = plot_data$CognitiveFunction
  )

  # Create color palette for CognitiveFunction subgroups
  subgroup_colors <- brewer.pal(length(unique(plot_data$CognitiveFunction)), "Blues")
  names(subgroup_colors) <- unique(plot_data$CognitiveFunction)

  # Create the forest plot using viz_forest
  viz_forest(
    x = cbind(plot_data$yi, plot_data$sei),
    variant= "thick",
    type = "sensitivity",
    study_labels = plot_data$PlotLabel,
    group = plot_data$CognitiveFunction,
    summary_label = names(subgroup_colors),
    col = subgroup_colors[1],
    summary_col = "darkblue",
    xlab = xlab_text,
    study_table = table_data,
    table_headers = c("Study", "Dose", "N", "Time point", "Cognitive Function"),
    table_layout = matrix(c(1, 2), nrow = 1)
  )
}

forest_plot(ACC = TRUE)
```

# 3.4.1.4 Subgroup Analyses RT
```{r moderation function}
# library(metafor)

moderation_analysis <- function(RT = FALSE, ACC = FALSE, moderation_var) {
    # Check that either RT or ACC is TRUE
    if (RT == TRUE && ACC == TRUE) {
        stop("Only one of RT or ACC should be TRUE")
    } else if (RT == FALSE && ACC == FALSE) {
        stop("At least one of RT or ACC should be TRUE")
    }

    # Select the appropriate data and columns based on RT or ACC
    if (RT) {
        data <- data_RT
        effect_size_col <- "ES_final_RT"
        variance_col <- "ES_var_RT"
    } else if (ACC) {
        data <- data_ACC
        effect_size_col <- "ES_final_ACC"
        variance_col <- "ES_var_ACC"
    }

    # Ensure the moderation variable exists in the data
    if (!moderation_var %in% names(data)) {
        stop(paste("The moderation variable", moderation_var, "is not in the dataset."))
    }

    # Convert moderation variable to a factor with specified reference category
    if (moderation_var == "EF_sensitivity") {
        data[[moderation_var]] <- factor(data[[moderation_var]], levels = c("3", "1", "2"))
    } else {
        data[[moderation_var]] <- as.factor(data[[moderation_var]])
    }
    if (moderation_var == "CognitiveFunction") {
        data[[moderation_var]] <- factor(data[[moderation_var]], levels = c("Attention", "Conflict monitoring", "Other EF", "Working Memory"))
    } else {
        data[[moderation_var]] <- as.factor(data[[moderation_var]])
    }


    # Running the mixed-effects model with moderation
    model <- rma.mv(
        yi = data[[effect_size_col]],
        V = data[[variance_col]],
        random = ~ 1 | ID / ES_ID,
        data = data,
        method = "REML",
        mods = as.formula(paste0("~", moderation_var))
    )

    # Return the summary of the model
    return(summary(model))
}
```


# 3.4.1.4.1 Timing as moderator RT

```{r Function to Code Timing in the dataset}
ClassifyTiming <- function(data, start_peak, stop_peak) {
    # Ensure 'data' is a data frame
    if (!is.data.frame(data)) {
        stop("The 'data' argument must be a data frame.")
    }

    # Check if the "Timepoint (min)" column exists in the data frame
    if (!"Timepoint" %in% names(data)) {
        stop("The data frame does not contain a 'Timepoint (min)' column.")
    }

    # Initialize the 'timing' column to 0
    data$timing <- 0

    # Retrieve the "Timepoint (min)" column
    timepoint_col <- data[["Timepoint"]]

    # Classify as pre-peak (coded as 1)
    data$timing[timepoint_col < start_peak] <- 1

    # Classify as post-peak (coded as 1)
    data$timing[timepoint_col > stop_peak] <- 1

    # Classify as during peak (neither pre-peak nor post-peak, coded as 0)
    data$timing[timepoint_col >= start_peak & timepoint_col <= stop_peak] <- 0

    return(data)
}
```

```{r peak window}	
#
data_RT <- ClassifyTiming(data_RT, start_peak = 90, stop_peak = 180)
data_RT$timing <- as.factor(data_RT$timing)
nrow(data_RT)
length(unique(data_RT$ID))

moderation_analysis(RT = TRUE, moderation_var = "timing")
```

# 3.4.1.4.2 Dosage as moderator RT
```{r Dosage}
moderation_analysis(RT = TRUE, moderation_var = "dosage_cat_all")
moderation_analysis(RT = TRUE, moderation_var = "dosage_cat_micro")
moderation_analysis(RT = TRUE, moderation_var = "dosage_cat_microlow_vs_midhigh")
```
# 3.4.1.4.3 Cognitive function as moderator RT
```{r moderation cognitive function category}
moderation_analysis(RT = TRUE, moderation_var = "CognitiveFunction")
table(data_RT$CognitiveFunction)
```
# 3.4.1.4.4 EF sensitivity as moderator RT
```{r moderation EF sensitivity}
moderation_analysis(RT = TRUE, moderation_var = "EF_sensitivity")
# table(data_RT$EF_sensitivity)
# head(data_RT)
```

# 3.4.1.4.5 Metaforest Analysis RT
```{r MetaForest Function}
# code adapted from (Van Lissa, 2017)

# Set a seed for reproducibility
set.seed(242)

run_metaforest_analysis <- function(data_type) {
    library(metaforest)
    library(dplyr)

    # Load and prepare data based on the specified data type
    if (data_type == "RT") {
        data_metaforest <- data_RT
        outcome_var <- "ES_final_RT"
        vi_variable <- "ES_var_RT"
        metaforest_formula <- ES_final_RT~CognitiveFunction + DoseLabel + EF_sensitivity + timing + dosage_cat_all
    } else if (data_type == "ACC") {
        data_metaforest <- data_ACC
        outcome_var <- "ES_final_ACC"
        vi_variable <- "ES_var_ACC"
        metaforest_formula <- ES_final_ACC~CognitiveFunction + DoseLabel + EF_sensitivity + timing + dosage_cat_all
    } else {
        stop("Invalid data type specified. Use 'RT' or 'ACC'.")
    }


    # Convert factor variables explicitly if not already
    data_metaforest$CognitiveFunction <- as.factor(data_metaforest$CognitiveFunction)
    data_metaforest$DoseLabel <- as.factor(data_metaforest$DoseLabel)
    data_metaforest$EF_sensitivity <- as.factor(data_metaforest$EF_sensitivity)
    data_metaforest$dosage_cat_all <- as.factor(data_metaforest$dosage_cat_all)

    data_metaforest$ID <- as.factor(data_metaforest$ID)
    data_metaforest$timing <- as.factor(data_metaforest$timing)
    data_metaforest$ES_ID <- as.factor(data_metaforest$ES_ID)

    # check for convergence
    check_conv <- MetaForest(
        formula = metaforest_formula,
        data = data_metaforest,
        study = "ID", # grouping variable, because we have multiple effect sizes per study
        vi = vi_variable,
        whichweights = "random",
        method = "REML",
        num.trees = 20000
    )
    # plot(check_conv)


    # rerun with reduced number of trees
    metaforest_reduced <- MetaForest(
        formula = metaforest_formula,
        data = data_metaforest,
        study = "ID", # grouping variable, because we have multiple effect sizes per study
        vi = vi_variable,
        whichweights = "random",
        method = "REML",
        num.trees = 5000
    )

    # Run recursive preselection to refine the selection of moderators
    preselected <- preselect(metaforest_reduced, replications = 300, algorithm = "recursive")
    # plot(preselected)  # Plot the results of the preselection

    # Retain only moderators with positive variable importance in more than 50% of replications
    retain_mods <- preselect_vars(preselected, cutoff = 0.5)

    # Print out the moderators that are retained
    # print(retain_mods)

    results <- list(
        model = metaforest_reduced,
        preselected = preselected,
        retained_mods = retain_mods,
        check_conv = check_conv
    )

    return(results)
}
```

```{r Figure S1 Convergence graph Metaforest RT}
retain_mods <- run_metaforest_analysis("RT")
conv <- retain_mods$check_conv
plot(conv)
```
```{r Figure S2 retained moderators RT}
# change nr of trees based on convergence!
retain_mods <- run_metaforest_analysis("RT")
plot(retain_mods$preselected)
print(retain_mods$retained_mods)
```

```{r fine tuning Metaforest}
# code adapted from (Van Lissa, 2017)
library(caret)
library(metaforest)

fine_tune_metaforest <- function(data_type, predictors) {
    library(metaforest)
    library(dplyr)

    # Load and prepare data based on the specified data type
    if (data_type == "RT") {
        data <- data_RT
        outcome_var <- "ES_final_RT"
        vi_variable <- "ES_var_RT"
    } else if (data_type == "ACC") {
        data <- data_ACC
        outcome_var <- "ES_final_ACC"
        vi_variable <- "ES_var_ACC"
    } else {
        stop("Invalid data type specified. Use 'RT' or 'ACC'.")
    }

    set.seed(78)

    # Prepare the training control using grouped cross-validation
    grouped_cv <- trainControl(
        method = "cv",
        index = groupKFold(data$ID, k = length(unique(data$ID)))
    )

    # Set up a tuning grid for MetaForest
    tuning_grid <- expand.grid(
        whichweights = c("random", "fixed", "unif"),
        mtry = 1:2,
        min.node.size = 1:5
    )

    # Define the predictors and outcome

    # Ensure the dataset has only the necessary columns
    X <- data[, c("ID", vi_variable, predictors)]
    data$ID <- as.factor(data$ID)
    data$EF_sensitivity <- as.factor(data$EF_sensitivity)

    # Train the model
    mf_cv <- train(
        x = X,
        y = data[[outcome_var]],
        vi = vi_variable,
        study = "ID", # Clustering variable
        method = ModelInfo_mf(),
        trControl = grouped_cv,
        tuneGrid = tuning_grid,
        num.trees = 15000
    )

    final <- mf_cv$finalModel
    r2_oob <- final$forest$r.squared
    r2_cv <- mf_cv$results$Rsquared[which.min(mf_cv$results$RMSE)]
    return(list(
        model = mf_cv,
        r2_cv = r2_cv,
        final = final,
        r2_oob = r2_oob
    ))
}
```

```{r Figure S3 Variable/Permutation Importance RT}
predictors <- c("EF_sensitivity", "CognitiveFunction") # adjust based on previous analysis

mf_cv <- fine_tune_metaforest("RT", predictors)
# Check the results
print(mf_cv$r2_oob)
print(mf_cv$r2_cv)
final <- mf_cv$final
print(final)
# variable importance plot
VarImpPlot(final)
```

```{r Figure S4 Partial Dependence Plot RT}
# partial dependence plot
PartialDependence(final, rawdata = TRUE, pi = .95)
```



```{r Figure S5 Moderated Partial Dependence Plot RT}
# moderated partial dependence plot
PartialDependence(final, moderator = "CognitiveFunction", rawdata = TRUE, pi = .95)
```

